{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Ref\n# https://huggingface.co/docs/evaluate/main/en/transformers_integrations\n# https://www.kaggle.com/code/fadyelkbeer/mt5-multilingual-xlsum\n# https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_&_Biases.ipynb\n# https://docs.wandb.ai/guides/integrations/huggingface","metadata":{"id":"33UfnSX2l0Aw","execution":{"iopub.status.busy":"2023-10-11T15:12:29.693242Z","iopub.execute_input":"2023-10-11T15:12:29.696562Z","iopub.status.idle":"2023-10-11T15:12:29.721262Z","shell.execute_reply.started":"2023-10-11T15:12:29.696518Z","shell.execute_reply":"2023-10-11T15:12:29.720341Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate rouge_score wandb transformers[torch] sentencepiece -q\n!pip install accelerate -U -q\n!pip install datasets -U -q","metadata":{"id":"WZaJCBzkl0Ax","execution":{"iopub.status.busy":"2023-10-11T15:12:29.728376Z","iopub.execute_input":"2023-10-11T15:12:29.730085Z","iopub.status.idle":"2023-10-11T15:13:02.393347Z","shell.execute_reply.started":"2023-10-11T15:12:29.730051Z","shell.execute_reply":"2023-10-11T15:13:02.392265Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ns3fs 2023.9.0 requires fsspec==2023.9.0, but you have fsspec 2023.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil","metadata":{"id":"BMRVww_P0oli","execution":{"iopub.status.busy":"2023-10-11T15:13:02.395107Z","iopub.execute_input":"2023-10-11T15:13:02.395442Z","iopub.status.idle":"2023-10-11T15:13:02.399739Z","shell.execute_reply.started":"2023-10-11T15:13:02.395410Z","shell.execute_reply":"2023-10-11T15:13:02.398914Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"continute_train = False # @param {type:\"boolean\"}","metadata":{"id":"MqV2-TYM33d7","execution":{"iopub.status.busy":"2023-10-11T15:13:02.402793Z","iopub.execute_input":"2023-10-11T15:13:02.403364Z","iopub.status.idle":"2023-10-11T15:13:02.414002Z","shell.execute_reply.started":"2023-10-11T15:13:02.403312Z","shell.execute_reply":"2023-10-11T15:13:02.413083Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Wandb Setup","metadata":{"id":"1WDPdk5jl0Ay"}},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"633eeb120e6c05fe397c3e72cd4fda73233e2b23\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0fAdk4fl0Ay","outputId":"2a49eb73-8398-41db-9a7d-ad197243ada9","execution":{"iopub.status.busy":"2023-10-11T15:13:02.415342Z","iopub.execute_input":"2023-10-11T15:13:02.415656Z","iopub.status.idle":"2023-10-11T15:13:06.020835Z","shell.execute_reply.started":"2023-10-11T15:13:02.415628Z","shell.execute_reply":"2023-10-11T15:13:06.019920Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# @title ##Initialize wandb\nproject_name = \"text-summarization-model\"\n\nrun = wandb.init(project=project_name, job_type=\"train\")#, name=run_name)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"FwEpGnvll0A0","outputId":"e4ed3173-2d4b-4f9c-e7b0-1e738ac94b9d","execution":{"iopub.status.busy":"2023-10-11T15:13:06.021982Z","iopub.execute_input":"2023-10-11T15:13:06.023147Z","iopub.status.idle":"2023-10-11T15:13:37.533292Z","shell.execute_reply.started":"2023-10-11T15:13:06.023115Z","shell.execute_reply":"2023-10-11T15:13:37.532443Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylanonwic\u001b[0m (\u001b[33mdylanon\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231011_151306-4y3k97is</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dylanon/text-summarization-model/runs/4y3k97is' target=\"_blank\">rich-shape-50</a></strong> to <a href='https://wandb.ai/dylanon/text-summarization-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dylanon/text-summarization-model' target=\"_blank\">https://wandb.ai/dylanon/text-summarization-model</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dylanon/text-summarization-model/runs/4y3k97is' target=\"_blank\">https://wandb.ai/dylanon/text-summarization-model/runs/4y3k97is</a>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Process data function","metadata":{"id":"v1GS15Cvl0Ay"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\", legacy=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxfOs4oyl0Az","outputId":"97c80ffb-d2b9-4e0d-8a04-796ec2e47ece","execution":{"iopub.status.busy":"2023-10-11T15:13:37.537319Z","iopub.execute_input":"2023-10-11T15:13:37.537933Z","iopub.status.idle":"2023-10-11T15:13:43.215927Z","shell.execute_reply.started":"2023-10-11T15:13:37.537902Z","shell.execute_reply":"2023-10-11T15:13:43.214847Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ccf09c8c4954d0d8ea024e2e8dbee69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/730 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606a33c63b824bfc97c3c517162a6185"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89425b06d24a4452939dc3654b0034ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca118d8088df43cd956cab6ef3dcd6e3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setup evaluation","metadata":{"id":"5XpJGQcrl0Az"}},{"cell_type":"code","source":"import nltk\nimport evaluate\nnltk.download(\"punkt\", quiet=True)\nmetric = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n\n    # decode preds and labels\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # rougeLSum expects newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    return result","metadata":{"id":"FYOAT5yYl0Az","execution":{"iopub.status.busy":"2023-10-11T15:13:43.217829Z","iopub.execute_input":"2023-10-11T15:13:43.218680Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Get model","metadata":{"id":"5AgLWixrl0Az"}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import DataCollatorForSeq2Seq\nfrom datasets import load_dataset\nimport datasets\nimport numpy as np","metadata":{"id":"rL_yWpW7l0Az","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = \"./imported_model\"\n\nif continute_train:\n\n    artifact = run.use_artifact('dylanon/text-summarization-model/summarization-model:latest', type='model')\n\n    if not os.path.exists(model_dir):\n        artifact_dir = artifact.download(root=model_dir)\n\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n\nelse:\n    model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\", cache_dir=model_dir)","metadata":{"id":"2Tm9_2j42P0n","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"id":"aCfoLiFFl0Az","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get datasets","metadata":{}},{"cell_type":"code","source":"# load dataset-artifact\nartifact_dir = './imported_datasets'\nuse_artifact = \"dylanon/text-summarization-model/tokenized-dataset:latest\"\n\nif not os.path.exists(artifact_dir):\n    artifact = run.use_artifact(use_artifact, type='dataset')\n    artifact_dir = artifact.download(root=artifact_dir)\n\ntokenized_dataset = datasets.load_from_disk(artifact_dir)\ntokenized_dataset = datasets.Dataset.from_dict(tokenized_dataset[:10_000])\ntokenized_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=False, seed=1150)","metadata":{"id":"R2cYwl-ltldQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train config","metadata":{"id":"guxDFuQvuXXr"}},{"cell_type":"code","source":"wandb.config = {\n    \"evaluation_strategy\":\"steps\",\n    \"auto_find_batch_size\" : True,\n#   \"per_device_train_batch_size\":32,\n#   \"per_device_eval_batch_size\":8,\n    \"learning_rate\":5e-4, # default 5e-4\n    \"warmup_steps\":50,\n    \"weight_decay\":0.01, # default 0.01\n#     \"lr_scheduler_type\":\"linear\",\n    \"gradient_accumulation_steps\":32,  #16\n    \"eval_accumulation_steps\":64,\n    \"gradient_checkpointing\":True,\n#   \"optim\":\"adamw_bnb_8bit\",\n    \"num_train_epochs\":1,\n#   \"max_steps\" :10000,\n\n    \"save_steps\":0,\n    \"eval_steps\":100,\n    \"logging_steps\":10,\n    \"save_total_limit\":0,\n    \"load_best_model_at_end\":False,\n    \"fp16\":True, # this can use with cuda only\n    \"predict_with_generate\":True,\n}","metadata":{"id":"x-dYybbqrYHo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train argment\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    report_to=\"wandb\",\n    **wandb.config\n)\n\ntrainer = Seq2SeqTrainer(\n    model = model,\n    args = training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)","metadata":{"id":"uTD1ylhBqCCQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title ##Train\nremove unused variable to free memory\nimport gc\nimport torch\n\n# train\nif continute_train: trainer.train(resume_from_checkpoint = './imported_model')\nelse: trainer.train()\n\n\ndirectory_path = \"./exported_model\"\n\n# Check if the directory exists\nif os.path.exists(directory_path):\n    try:\n        # Delete the directory and its contents\n        shutil.rmtree(directory_path)\n        print(f\"Directory '{directory_path}' deleted successfully.\")\n    except Exception as e:\n        print(f\"Error deleting '{directory_path}': {str(e)}\")\n    \n\n# export model to file\ntrainer.save_model(directory_path)","metadata":{"id":"lDE6jhP5qEGj","colab":{"base_uri":"https://localhost:8080/","height":545},"outputId":"2f0ef495-0ba6-4f7b-8479-614e7c334820","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import gc\n# from torch import cuda\n# cuda.empty_cache()\n# gc.collect()","metadata":{"id":"rpdiJtntWJ41","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title ##Evaluation\nevaluation_results = trainer.evaluate()#eval_dataset=dataset['test'])\nevaluation_results","metadata":{"id":"cEdo-4RXwSO5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title ##Upload model to wandb\nart = wandb.Artifact(f\"summarization-model\", type=\"model\")\n\nfor dir in os.listdir(\"./exported_model\"):\n    art.add_file(os.path.join( \"./exported_model\" , dir))\n\nwandb.log(evaluation_results)\nwandb.log_artifact(art)","metadata":{"id":"VhwLkLpcl0A0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from time import time\n# from google.colab import runtime\n# time.sleep(300)\n# runtime.unassign()","metadata":{"id":"t2rlxnISF9Op","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}