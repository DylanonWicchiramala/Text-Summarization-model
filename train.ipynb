{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:51:45.111382Z","iopub.status.busy":"2023-10-08T13:51:45.111039Z","iopub.status.idle":"2023-10-08T13:51:45.116868Z","shell.execute_reply":"2023-10-08T13:51:45.115760Z","shell.execute_reply.started":"2023-10-08T13:51:45.111355Z"},"trusted":true},"outputs":[],"source":["# Ref\n","# https://huggingface.co/docs/evaluate/main/en/transformers_integrations\n","# https://www.kaggle.com/code/fadyelkbeer/mt5-multilingual-xlsum\n","# https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_&_Biases.ipynb\n","# https://docs.wandb.ai/guides/integrations/huggingface"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:51:45.147531Z","iopub.status.busy":"2023-10-08T13:51:45.146823Z","iopub.status.idle":"2023-10-08T13:51:57.500801Z","shell.execute_reply":"2023-10-08T13:51:57.499518Z","shell.execute_reply.started":"2023-10-08T13:51:45.147508Z"},"trusted":true},"outputs":[],"source":["%pip install evaluate rouge_score -q"]},{"cell_type":"markdown","metadata":{},"source":["# Wandb Setup"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:51:57.503666Z","iopub.status.busy":"2023-10-08T13:51:57.502980Z","iopub.status.idle":"2023-10-08T13:52:00.343662Z","shell.execute_reply":"2023-10-08T13:52:00.342630Z","shell.execute_reply.started":"2023-10-08T13:51:57.503628Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","from kaggle_secrets import UserSecretsClient\n","\n","user_secrets = UserSecretsClient()\n","\n","# I have saved my API token with \"wandb_api\" as Label. \n","# If you use some other Label make sure to change the same below. \n","wandb_api = user_secrets.get_secret(\"wandb_api\") \n","\n","wandb.login(key=wandb_api)"]},{"cell_type":"markdown","metadata":{},"source":["# Process data function"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:52:00.345670Z","iopub.status.busy":"2023-10-08T13:52:00.345141Z","iopub.status.idle":"2023-10-08T13:52:04.541033Z","shell.execute_reply":"2023-10-08T13:52:04.540015Z","shell.execute_reply.started":"2023-10-08T13:52:00.345626Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15a52659d9aa4943bce6236e910064cf","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ff183d935b44230a92bc90be98d1b99","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/730 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d7f3a4324214494bbeea7b59220cab1","version_major":2,"version_minor":0},"text/plain":["Downloading spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2f0cb0182284996b8b09306632b0328","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoTokenizer\n","import re\n","tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\",legacy=False)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:52:04.544262Z","iopub.status.busy":"2023-10-08T13:52:04.543740Z","iopub.status.idle":"2023-10-08T13:52:04.551445Z","shell.execute_reply":"2023-10-08T13:52:04.550079Z","shell.execute_reply.started":"2023-10-08T13:52:04.544226Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(dataset):\n","    text_token_len = 512\n","    sum_token_len = 100\n","    # Convert the text and summary columns to tensors.\n","    input_text = dataset[\"text\"]\n","    target_text = dataset[\"sum\"]\n","\n","    # this line just follow model card in huggingface\n","    WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n","    input_text = [WHITESPACE_HANDLER(text) for text in input_text]\n","    \n","    # Tokenize the input and target text.\n","    text_token = tokenizer(input_text, truncation=True, padding=True, max_length=text_token_len)\n","    sum_token = tokenizer(target_text, truncation=True, padding=True, max_length=sum_token_len)\n","\n","    # model input\n","    model_inputs = text_token\n","    model_inputs[\"labels\"] = sum_token[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"markdown","metadata":{},"source":["# Setup evaluation"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:52:04.553835Z","iopub.status.busy":"2023-10-08T13:52:04.552964Z","iopub.status.idle":"2023-10-08T13:52:19.381974Z","shell.execute_reply":"2023-10-08T13:52:19.381122Z","shell.execute_reply.started":"2023-10-08T13:52:04.553797Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6971b240bbea44ba82fc0454c1bb29ad","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import nltk\n","import evaluate\n","nltk.download(\"punkt\", quiet=True)\n","metric = evaluate.load(\"rouge\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:52:19.384642Z","iopub.status.busy":"2023-10-08T13:52:19.383456Z","iopub.status.idle":"2023-10-08T13:52:19.397898Z","shell.execute_reply":"2023-10-08T13:52:19.397018Z","shell.execute_reply.started":"2023-10-08T13:52:19.384607Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","\n","    # decode preds and labels\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # rougeLSum expects newline after each sentence\n","    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    return result"]},{"cell_type":"markdown","metadata":{},"source":["# Train model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:52:19.400252Z","iopub.status.busy":"2023-10-08T13:52:19.399336Z","iopub.status.idle":"2023-10-08T13:52:19.436448Z","shell.execute_reply":"2023-10-08T13:52:19.435630Z","shell.execute_reply.started":"2023-10-08T13:52:19.400199Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers import DataCollatorForSeq2Seq\n","from datasets import load_dataset\n","import numpy as np"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:52:19.437913Z","iopub.status.busy":"2023-10-08T13:52:19.437448Z","iopub.status.idle":"2023-10-08T13:53:48.675013Z","shell.execute_reply":"2023-10-08T13:53:48.673948Z","shell.execute_reply.started":"2023-10-08T13:52:19.437884Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3748c0fd1b77461b86a60b08f256a445","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/mT5_multilingual_XLSum\")\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T13:53:48.678798Z","iopub.status.busy":"2023-10-08T13:53:48.678511Z","iopub.status.idle":"2023-10-08T14:04:18.239580Z","shell.execute_reply":"2023-10-08T14:04:18.236750Z","shell.execute_reply.started":"2023-10-08T13:53:48.678773Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m63050123\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.15.12 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231008_135348-uxtyf4qm</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/63050123/text-summarization-model/runs/uxtyf4qm' target=\"_blank\">vital-galaxy-11</a></strong> to <a href='https://wandb.ai/63050123/text-summarization-model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/63050123/text-summarization-model' target=\"_blank\">https://wandb.ai/63050123/text-summarization-model</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/63050123/text-summarization-model/runs/uxtyf4qm' target=\"_blank\">https://wandb.ai/63050123/text-summarization-model/runs/uxtyf4qm</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact slices:v2, 6632.04MB. 11 files... \n","\u001b[34m\u001b[1mwandb\u001b[0m:   11 of 11 files downloaded.  \n","Done. 0:0:26.5\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset parquet/default to /root/.cache/huggingface/datasets/parquet/default-ed68884e7a518a50/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19daa0c0a3d440d6a829abccf38ed19a","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b786a4afe59d4c81863fb72d19c1166d","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/default-ed68884e7a518a50/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d44f8a441bd84499917551434812ee61","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9b413182d3b4f60aa82cf6fc03690cd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6ed268d94bb4ae09f616745fa636d59","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='51' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 51/100 00:49 < 00:49, 0.99 it/s, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>3.183173</td>\n","      <td>0.360435</td>\n","      <td>0.139613</td>\n","      <td>0.332533</td>\n","      <td>0.331590</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 03:52, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Rougel</th>\n","      <th>Rougelsum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.796121</td>\n","      <td>0.382214</td>\n","      <td>0.162603</td>\n","      <td>0.361021</td>\n","      <td>0.361516</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.739464</td>\n","      <td>0.390615</td>\n","      <td>0.172929</td>\n","      <td>0.369338</td>\n","      <td>0.369474</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset parquet/default to /root/.cache/huggingface/datasets/parquet/default-a1b4b9c41d8eef6c/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6020371389524361a021b4a4b2f981ba","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f994be468e044b58ff806079ef1fdf5","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/default-a1b4b9c41d8eef6c/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9393fb3689ad41799d9405c8acc0207a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d843fd665ee4f788428062b9a7aff60","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▁</td></tr><tr><td>eval/rouge1</td><td>▁▆█</td></tr><tr><td>eval/rouge2</td><td>▁▆█</td></tr><tr><td>eval/rougeL</td><td>▁▆█</td></tr><tr><td>eval/rougeLsum</td><td>▁▇█</td></tr><tr><td>eval/runtime</td><td>█▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁▇█</td></tr><tr><td>train/epoch</td><td>▁▁██</td></tr><tr><td>train/global_step</td><td>▁▃██</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.73946</td></tr><tr><td>eval/rouge1</td><td>0.39062</td></tr><tr><td>eval/rouge2</td><td>0.17293</td></tr><tr><td>eval/rougeL</td><td>0.36934</td></tr><tr><td>eval/rougeLsum</td><td>0.36947</td></tr><tr><td>eval/runtime</td><td>19.906</td></tr><tr><td>eval/samples_per_second</td><td>10.047</td></tr><tr><td>eval/steps_per_second</td><td>0.653</td></tr><tr><td>train/epoch</td><td>2.0</td></tr><tr><td>train/global_step</td><td>200</td></tr><tr><td>train/total_flos</td><td>430007918985216.0</td></tr><tr><td>train/train_loss</td><td>3.13101</td></tr><tr><td>train/train_runtime</td><td>232.9091</td></tr><tr><td>train/train_samples_per_second</td><td>6.87</td></tr><tr><td>train/train_steps_per_second</td><td>0.859</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">vital-galaxy-11</strong> at: <a href='https://wandb.ai/63050123/text-summarization-model/runs/uxtyf4qm' target=\"_blank\">https://wandb.ai/63050123/text-summarization-model/runs/uxtyf4qm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20231008_135348-uxtyf4qm/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(preprocess_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(tokenized_dataset)\n\u001b[0;32m---> 49\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# log metrics to wandb\u001b[39;00m\n\u001b[1;32m     52\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog(metrics)\n","Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_preds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(eval_preds):\n\u001b[0;32m----> 2\u001b[0m     preds, labels \u001b[38;5;241m=\u001b[39m eval_preds\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# decode preds and labels\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, labels, tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["project_name = \"text-summarization-model\"\n","use_artifact = \"dylanon/text-summarization-model/slices:v2\"\n","train_dataset = \"slice_0.parquet\"\n","train_rows = 10000\n","run_name = \"demo\"\n","# with wandb.init(project=project_name) as run:\n","\n","run = wandb.init(project=project_name, name=run_name, job_type=\"train\")\n","\n","# load dataset-artifact\n","artifact = run.use_artifact(\"dylanon/text-summarization-model/slices:v2\", type='dataset')\n","artifact_dir = artifact.download()\n","    \n","# read artifact\n","dataset = load_dataset('parquet',data_files=(artifact_dir + \"/\" + train_dataset), split=\"train[:{}]\".format(train_rows))\n","dataset = dataset.train_test_split(test_size=0.2)\n","    \n","# prepare data\n","tokenized_dataset = dataset.map(preprocess_function, batched=True)\n","    \n","# train\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    report_to=\"wandb\",\n","    auto_find_batch_size = True,\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=2,\n","    fp16=True, # this can use with cuda only\n","    predict_with_generate=True,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model = model,\n","    args = training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")\n","\n","# remove unused variable to free memory\n","import gc\n","import torch\n","\n","del dataset\n","del tokenized_dataset\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","# train\n","trainer.train()\n","\n","# export model to file\n","trainer.save_model(\"./exported_model\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
